{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPf6PDLG4QZkK1uHfrZZdrK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Named Entity Recognition (NER)"],"metadata":{"id":"Ynf-_Uy6PIFq"}},{"cell_type":"markdown","source":["Named Entity means anything that is a real-world object such as a person, a place, any organisation, any product which has a name. For example – “My name is Raj, and I and a Machine Learning Trainer”. In this sentence the name “Raj”, the field or subject “Machine Learning” and the profession “Trainer” are named entities."],"metadata":{"id":"ZXVyfDnLPNZi"}},{"cell_type":"markdown","source":["In Machine Learning Named Entity Recognition (NER) is a task of Natural Language Processing to identify the named entities in a certain piece of text.\n","\n","Have you ever used software known as Grammarly? It identifies all the incorrect spellings and punctuations in the text and corrects it. But it does not do anything with the named entities, as it is also using the same technique"],"metadata":{"id":"BAi0WgVVPagj"}},{"cell_type":"markdown","source":["**Dataset:-** [Name Entity Recognition (NER) Dataset](https://www.kaggle.com/datasets/debasisdotcom/name-entity-recognition-ner-dataset)"],"metadata":{"id":"QaRBZ70lPdpY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Dhdn0rKORB1"},"outputs":[],"source":["# import libraries\n","\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["!pip install opendatasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9Mu4X4fRuJr","executionInfo":{"status":"ok","timestamp":1671778513052,"user_tz":-330,"elapsed":4429,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"5638df88-68c3-4a0d-f722-3d348b11f1e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from opendatasets) (4.64.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from opendatasets) (7.1.2)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (from opendatasets) (1.5.12)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.15.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2022.12.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.23.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (7.0.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (2.10)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n"]}]},{"cell_type":"code","source":["import opendatasets as od\n","import pandas as pd\n","\n","od.download(\n","\t\"https://www.kaggle.com/datasets/debasisdotcom/name-entity-recognition-ner-dataset\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wr763iKqRuMh","executionInfo":{"status":"ok","timestamp":1671778547414,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"86226afa-742f-48d6-f38c-7a69ed6b1835"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping, found downloaded files in \"./name-entity-recognition-ner-dataset\" (use force=True to force download)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","data = pd.read_csv('/content/name-entity-recognition-ner-dataset/NER dataset.csv', encoding = 'unicode_escape')\n","data"],"metadata":{"id":"hA-aoCQiSKY9","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1671778548474,"user_tz":-330,"elapsed":543,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"735349e1-c447-436a-8646-f0528d5e7c2b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Sentence #           Word  POS Tag\n","0        Sentence: 1      Thousands  NNS   O\n","1                NaN             of   IN   O\n","2                NaN  demonstrators  NNS   O\n","3                NaN           have  VBP   O\n","4                NaN        marched  VBN   O\n","...              ...            ...  ...  ..\n","1048570          NaN           they  PRP   O\n","1048571          NaN      responded  VBD   O\n","1048572          NaN             to   TO   O\n","1048573          NaN            the   DT   O\n","1048574          NaN         attack   NN   O\n","\n","[1048575 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-a337a1d4-2717-438b-a879-6d9418b1a2b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1048570</th>\n","      <td>NaN</td>\n","      <td>they</td>\n","      <td>PRP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048571</th>\n","      <td>NaN</td>\n","      <td>responded</td>\n","      <td>VBD</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048572</th>\n","      <td>NaN</td>\n","      <td>to</td>\n","      <td>TO</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048573</th>\n","      <td>NaN</td>\n","      <td>the</td>\n","      <td>DT</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1048574</th>\n","      <td>NaN</td>\n","      <td>attack</td>\n","      <td>NN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1048575 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a337a1d4-2717-438b-a879-6d9418b1a2b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a337a1d4-2717-438b-a879-6d9418b1a2b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a337a1d4-2717-438b-a879-6d9418b1a2b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFB2dH6rS9fc","executionInfo":{"status":"ok","timestamp":1671778548478,"user_tz":-330,"elapsed":41,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"50fe3c61-22b1-41b7-a23d-819f4a55d86c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1048575, 4)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kulITwSvTb4X","executionInfo":{"status":"ok","timestamp":1671778549268,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"c10eba4b-92ad-4392-9315-3fc69d7e3b67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1048575 entries, 0 to 1048574\n","Data columns (total 4 columns):\n"," #   Column      Non-Null Count    Dtype \n","---  ------      --------------    ----- \n"," 0   Sentence #  47959 non-null    object\n"," 1   Word        1048575 non-null  object\n"," 2   POS         1048575 non-null  object\n"," 3   Tag         1048575 non-null  object\n","dtypes: object(4)\n","memory usage: 32.0+ MB\n"]}]},{"cell_type":"markdown","source":["### Data Preparation for Neural Networks\n","I will train a Neural Network for the task of Named Entity Recognition (NER). So we need to do some modifications in the data to prepare it in such a manner so that it can easily fit into a neutral network. I will start this step by extracting the mappings that are required to train the neural network:"],"metadata":{"id":"Lp8-MCbYTlbp"}},{"cell_type":"code","source":["from itertools import chain\n","\n","def get_dict_map(data, token_or_tag):\n","  tok2idx = {}\n","  idx2tok = {}\n","\n","  if token_or_tag == 'token':\n","    vocab = list(set(data['Word'].to_list()))\n","  else:\n","    vocab = list(set(data['Tag'].to_list()))\n","\n","  idx2tok = {idx:tok for idx, tok in enumerate(vocab)}\n","  tok2idx = {tok:idx for idx, tok in enumerate(vocab)}\n","  return tok2idx, idx2tok\n","\n","token2idx, idx2token = get_dict_map(data, 'token')\n","tag2idx, idx2tag = get_dict_map(data, 'tag')"],"metadata":{"id":"R20lU01NTeh_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, transform the columns in the data to extract the sequential data for our neural network:"],"metadata":{"id":"blRB3NwPUr2N"}},{"cell_type":"code","source":["data['Word_idx'] = data['Word'].map(token2idx)\n","data['Tag_idx'] = data['Tag'].map(tag2idx)\n","data_fillna = data.fillna(method='ffill', axis=0)\n","# Groupby and collect columns\n","data_group = data_fillna.groupby(\n","['Sentence #'],as_index=False\n",")['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"],"metadata":{"id":"ctFNFXx7UpQ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671778578818,"user_tz":-330,"elapsed":4070,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"0d0784ae-5787-48c7-afe5-13e05b000579"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-f8b936d5d036>:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n","  data_group = data_fillna.groupby(\n"]}]},{"cell_type":"markdown","source":["Now, split the data into training and test sets. I will create a function for splitting the data because the LSTM layers accept sequences of the same length only. So every sentence that appears as integer in the data must be padded with the same length:"],"metadata":{"id":"PNmpR-H4xMa5"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","\n","def get_pad_train_test_val(data_group, data):\n","\n","    #get max token and tag length\n","    n_token = len(list(set(data['Word'].to_list())))\n","    n_tag = len(list(set(data['Tag'].to_list())))\n","\n","    #Pad tokens (X var)    \n","    tokens = data_group['Word_idx'].tolist()\n","    maxlen = max([len(s) for s in tokens])\n","    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n","\n","    #Pad Tags (y var) and convert it into one hot encoding\n","    tags = data_group['Tag_idx'].tolist()\n","    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n","    n_tags = len(tag2idx)\n","    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n","    \n","    #Split train, test and validation set\n","    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n","    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n","\n","    print(\n","        'train_tokens length:', len(train_tokens),\n","        '\\ntrain_tokens length:', len(train_tokens),\n","        '\\ntest_tokens length:', len(test_tokens),\n","        '\\ntest_tags:', len(test_tags),\n","        '\\nval_tokens:', len(val_tokens),\n","        '\\nval_tags:', len(val_tags),\n","    )\n","    \n","    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags\n","\n","train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data_group, data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rND2Ax9cxJyP","executionInfo":{"status":"ok","timestamp":1671778728389,"user_tz":-330,"elapsed":1676,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"1b0b5417-f21f-478f-91da-4d4eca26dfa5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_tokens length: 32372 \n","train_tokens length: 32372 \n","test_tokens length: 4796 \n","test_tags: 4796 \n","val_tokens: 10791 \n","val_tags: 10791\n"]}]},{"cell_type":"markdown","source":["### Training Neural Network for NER"],"metadata":{"id":"SKARSyIfx2aq"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow\n","from tensorflow.keras import Sequential, Model, Input\n","from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n","from tensorflow.keras.utils import plot_model\n","from numpy.random import seed\n","seed(1)\n","tensorflow.random.set_seed(2)"],"metadata":{"id":"hiXkE0jixXC9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The layer below will take the dimensions from the LSTM layer and will give the maximum length and maximum tags as an output:"],"metadata":{"id":"se_kWq3-x-3t"}},{"cell_type":"code","source":["input_dim = len(list(set(data['Word'].to_list())))+1\n","output_dim = 64\n","input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n","n_tags = len(tag2idx)"],"metadata":{"id":"-c73HX18x8cn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, create a helper function which will help us in giving the summary of every layer of the neural network model for Named Entity Recognition (NER):"],"metadata":{"id":"XGO3iB3zy2dC"}},{"cell_type":"code","source":["def get_bilstm_lstm_model():\n","    model = Sequential()\n","\n","    # Add Embedding layer\n","    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n","\n","    # Add bidirectional LSTM\n","    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n","\n","    # Add LSTM\n","    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n","\n","    # Add timeDistributed Layer\n","    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n","\n","    #Optimiser \n","    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n","\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","    \n","    return model"],"metadata":{"id":"4MIbnWMvyAyg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, create a helper function to train the Named Entity Recognition model:"],"metadata":{"id":"RCyPJ5uizL8N"}},{"cell_type":"code","source":["def train_model(X, y, model):\n","    loss = list()\n","    for i in range(25):\n","        # fit model for one epoch on this sequence\n","        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n","        loss.append(hist.history['loss'][0])\n","    return loss"],"metadata":{"id":"bk31dc8bzJFa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = pd.DataFrame()\n","model_bilstm_lstm = get_bilstm_lstm_model()\n","plot_model(model_bilstm_lstm)\n","results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERglUQO1zPvd","executionInfo":{"status":"ok","timestamp":1671783725605,"user_tz":-330,"elapsed":4589056,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"3ff501a6-d353-4851-c1b8-91d49a21dcbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 104, 64)           2251456   \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 104, 128)         66048     \n"," l)                                                              \n","                                                                 \n"," lstm_1 (LSTM)               (None, 104, 64)           49408     \n","                                                                 \n"," time_distributed (TimeDistr  (None, 104, 17)          1105      \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 2,368,017\n","Trainable params: 2,368,017\n","Non-trainable params: 0\n","_________________________________________________________________\n","26/26 [==============================] - 182s 7s/step - loss: 0.9864 - accuracy: 0.9180 - val_loss: 0.5729 - val_accuracy: 0.9679\n","26/26 [==============================] - 158s 6s/step - loss: 0.4345 - accuracy: 0.9670 - val_loss: 0.3178 - val_accuracy: 0.9681\n","26/26 [==============================] - 158s 6s/step - loss: 0.3112 - accuracy: 0.9677 - val_loss: 0.2855 - val_accuracy: 0.9681\n","26/26 [==============================] - 165s 6s/step - loss: 0.2948 - accuracy: 0.9677 - val_loss: 0.2777 - val_accuracy: 0.9681\n","26/26 [==============================] - 161s 6s/step - loss: 0.2834 - accuracy: 0.9677 - val_loss: 0.2638 - val_accuracy: 0.9681\n","26/26 [==============================] - 165s 6s/step - loss: 0.2740 - accuracy: 0.9677 - val_loss: 0.2595 - val_accuracy: 0.9681\n","26/26 [==============================] - 164s 6s/step - loss: 0.3287 - accuracy: 0.9677 - val_loss: 0.3133 - val_accuracy: 0.9681\n","26/26 [==============================] - 163s 6s/step - loss: 0.2790 - accuracy: 0.9677 - val_loss: 0.2591 - val_accuracy: 0.9681\n","26/26 [==============================] - 161s 6s/step - loss: 0.2617 - accuracy: 0.9677 - val_loss: 0.2528 - val_accuracy: 0.9681\n","26/26 [==============================] - 162s 6s/step - loss: 0.2559 - accuracy: 0.9677 - val_loss: 0.2503 - val_accuracy: 0.9681\n","26/26 [==============================] - 162s 6s/step - loss: 0.2500 - accuracy: 0.9677 - val_loss: 0.2416 - val_accuracy: 0.9681\n","26/26 [==============================] - 160s 6s/step - loss: 0.2199 - accuracy: 0.9677 - val_loss: 0.2103 - val_accuracy: 0.9681\n","26/26 [==============================] - 163s 6s/step - loss: 0.2086 - accuracy: 0.9678 - val_loss: 0.2054 - val_accuracy: 0.9681\n","26/26 [==============================] - 161s 6s/step - loss: 0.1954 - accuracy: 0.9678 - val_loss: 0.1988 - val_accuracy: 0.9681\n","26/26 [==============================] - 162s 6s/step - loss: 0.1709 - accuracy: 0.9678 - val_loss: 0.1628 - val_accuracy: 0.9681\n","26/26 [==============================] - 160s 6s/step - loss: 0.1577 - accuracy: 0.9678 - val_loss: 0.1556 - val_accuracy: 0.9681\n","26/26 [==============================] - 160s 6s/step - loss: 0.1535 - accuracy: 0.9678 - val_loss: 0.1534 - val_accuracy: 0.9681\n","26/26 [==============================] - 161s 6s/step - loss: 0.1663 - accuracy: 0.9678 - val_loss: 0.1637 - val_accuracy: 0.9682\n","26/26 [==============================] - 165s 6s/step - loss: 0.1532 - accuracy: 0.9678 - val_loss: 0.1557 - val_accuracy: 0.9681\n","26/26 [==============================] - 161s 6s/step - loss: 0.1479 - accuracy: 0.9678 - val_loss: 0.1512 - val_accuracy: 0.9682\n","26/26 [==============================] - 162s 6s/step - loss: 0.1429 - accuracy: 0.9679 - val_loss: 0.1486 - val_accuracy: 0.9682\n","26/26 [==============================] - 168s 6s/step - loss: 0.1403 - accuracy: 0.9679 - val_loss: 0.1466 - val_accuracy: 0.9682\n","26/26 [==============================] - 163s 6s/step - loss: 0.1340 - accuracy: 0.9679 - val_loss: 0.1388 - val_accuracy: 0.9682\n","26/26 [==============================] - 161s 6s/step - loss: 0.1296 - accuracy: 0.9680 - val_loss: 0.1368 - val_accuracy: 0.9683\n","26/26 [==============================] - 160s 6s/step - loss: 0.1229 - accuracy: 0.9680 - val_loss: 0.1333 - val_accuracy: 0.9683\n"]}]},{"cell_type":"markdown","source":["### Testing NER model"],"metadata":{"id":"vgsVmZjOzbqf"}},{"cell_type":"code","source":["import spacy\n","from spacy import displacy\n","nlp = spacy.load('en_core_web_sm')\n","text = nlp('Hi, My name is Ramesh \\n I am from India \\n I want to work with Google \\n Steve Jobs is My Inspiration')\n","displacy.render(text, style = 'ent', jupyter=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"dpkHWZajzS8W","executionInfo":{"status":"ok","timestamp":1671783732521,"user_tz":-330,"elapsed":6942,"user":{"displayName":"Ramesh D Koppad","userId":"09955402310140774456"}},"outputId":"43d1190f-dc1c-4b10-8e47-108ba308c400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi, My name is Ramesh </br> I am from \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    India\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n"," </br> I want to work with \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Google\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," </br> \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Steve Jobs\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," is My Inspiration</div></span>"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"_cvhS4IuzkAa"},"execution_count":null,"outputs":[]}]}